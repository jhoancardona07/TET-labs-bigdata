# Crear el clúster de EMR con la configuración necesaria para estos laboratorios:
aws emr create-cluster --auto-scaling-role EMR_AutoScaling_DefaultRole --applications Name=Hadoop Name=Hive Name=Hue Name=Spark Name=Zeppelin Name=Tez Name=Sqoop Name=Livy Name=Oozie --ebs-root-volume-size 10 --ec2-attributes '{"KeyName":"laboratorios-bigdata","InstanceProfile":"EMR_EC2_DefaultRole","SubnetId":"subnet-0e16af334a8a85887","EmrManagedSlaveSecurityGroup":"sg-0a591da663c1d0d29","EmrManagedMasterSecurityGroup":"sg-02d06e7f4402f4032"}' --service-role EMR_DefaultRole --enable-debugging --release-label emr-5.27.0 --log-uri 's3n://aws-logs-377171113952-us-east-1/elasticmapreduce/' --name 'labsEMR' --instance-groups '[{"InstanceCount":2,"EbsConfiguration":{"EbsBlockDeviceConfigs":[{"VolumeSpecification":{"SizeInGB":32,"VolumeType":"gp2"},"VolumesPerInstance":2}]},"InstanceGroupType":"CORE","InstanceType":"m4.xlarge","Name":"Principal - 2"},{"InstanceCount":1,"EbsConfiguration":{"EbsBlockDeviceConfigs":[{"VolumeSpecification":{"SizeInGB":32,"VolumeType":"gp2"},"VolumesPerInstance":2}]},"InstanceGroupType":"MASTER","InstanceType":"m4.xlarge","Name":"Maestro - 1"}]' --scale-down-behavior TERMINATE_AT_TASK_COMPLETION --region us-east-1

# Destruir el clúster de EMR creado con anterioridad mediante la AWS CLI usando su ID:
aws emr terminate-clusters --cluster-ids <clusterID>

# Conexión ssh al clúster de EMR:
ssh -i ~/laboratorios-bigdata.pem hadoop@ec2-54-173-82-228.compute-1.amazonaws.com

# Configuración del ambiente de trabajo
## Instalación de mrjob (Python y pip ya se encuentran instalados):
sudo pip install mrjob

## Clonación del repositorio
sudo yum install -y git
git clone https://github.com/jhoancardona07/TET-labs-bigdata.git

## Correr el WordCount sin MR:
python ./files/wordcount-local.py ../datasets/gutenberg-small/*.txt > ./files/wordcount-output-emr-local.txt

## Correr el WordCount con MR:
python ./files/wordcount-mr.py ../datasets/gutenberg-small/*.txt > ./files/wordcount-output-emr-mr.txt

## Correr los ejercicios hechos del laboratorio de Map/Reduce:
python labMR-1-1.py ../datasets/otros/dataempleados.csv
python labMR-1-2.py ../datasets/otros/dataempleados.csv
python labMR-1-3.py ../datasets/otros/dataempleados.csv

## Correr MRJob en EMR con entrada y salida en S3
### Es necesario instalar boto3 para tener acceso a los buckets de S3 de nuestra cuenta
sudo pip install boto3

### Configurar la aws cli como se vió en el video del curso con las credenciales de la cuenta y la sección actual
python files/wordcount-mr.py -r emr s3:///jscardonag/datasets/gutenberg-small/*.txt --output-dir s3:///jscardonag/result

