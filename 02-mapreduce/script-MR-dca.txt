# Configuración y scripts requeridos para correr el laboratorio de Map/Reduce en el DCA #

## Configuración inicial del entorno de trabajo
### Python, pip y mrjob ya se encuentran instalados en el DCA
### Clonación del repositorio con los archivos necesarios
git clone https://github.com/jhoancardona07/TET-labs-bigdata.git

## Correr el WordCount sin MR:
python ./files/wordcount-local.py ../datasets/gutenberg-small/*.txt > ./files/wordcount-output-local.txt

## Correr el WordCount con MR:
python ./files/wordcount-mr.py ../datasets/gutenberg-small/*.txt > ./files/wordcount-output-mr.txt

## Correr MRJob en el DCA con entrada y salida en HDFS
### Dentro de la carpeta 02-mapreduce clonada en el repositorio copiar el archivo de hadoop streaming de la siguiente ruta:
hdfs dfs -get /hdp/apps/3.1.4.0-315/mapreduce/hadoop-streaming.jar
### Ejecutar el mrjob
python wordcount-mr.py -r hadoop hdfs:///user/jscardonag/datasets/gutenberg-small/*.txt --output-dir hdfs:///user/jscardonag/results1 --hadoop-streaming-jar ./hadoop-streaming.jar 
